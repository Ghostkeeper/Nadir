/*
 * Strategy pattern optimiser with compile-time linear regression.
 * Copyright (C) 2020 Ghostkeeper
 * This library is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
 * This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for details.
 * You should have received a copy of the GNU Affero General Public License along with this library. If not, see <https://gnu.org/licenses/>.
 */

#ifndef NADIR_BENCHMARKER
#define NADIR_BENCHMARKER

#include <fstream> //To write the benchmark data to file.
#include <functional> //To register functions to be tested.
#include <stdlib.h> //For exit() in case an error occurs.
#include <string> //To identify options.
#include <vector> //To store the options and benchmark data.

namespace nadir {

/*!
 * This class allows the user of the Nadir library to create a benchmarking
 * application with relative ease.
 * \tparam Param A list of parameters. Any number of parameters is allowed. All
 * parameters must be serialisable to a file stream.
 */
template<typename... Param>
class Benchmarker {
public:
	/*!
	 * Add an algorithm for the optimiser to choose from.
	 *
	 * Add an algorithm that could be optimal for some set of parameters or on
	 * some combination of hardware. The algorithm will be one of the possible
	 * outputs of Nadir.
	 * \param identifier A unique string you want to recognise this option by.
	 * The output of Nadir will be one of these identifiers so that your code
	 * can know which algorithm to run. It will also be used to store the
	 * benchmark data in the generated data header.
	 * \param experiment An experiment to run to benchmark the algorithm. This
	 * can be a lambda function. The experiment must take the appropriate set of
	 * parameters.
	 */
	void add_option(const std::string& identifier, std::function<void(Param...)> experiment) {
		options.emplace_back(identifier, experiment);
	}

	/*!
	 * Run the benchmarks and save the results in the specified file name.
	 */
	void run(const std::string& output_filename) {
		std::fstream output_file;
		output_file.open(output_filename, std::ios::out);
		if(!output_file) {
			exit(1); //Can't open file for writing.
			return;
		}
		output_file << "//Benchmark file generated by Nadir benchmarker.\n";

		//TODO: Generate default parameter ranges where range is empty.
		//TODO: Run each experiment.
	}

protected:
	/*!
	 * The list of options for the strategy pattern to choose from.
	 *
	 * The benchmark will be ran for each of these options in order to get
	 * comparative results.
	 * Each option consists of an identifier (string) and an experiment to run.
	 */
	std::vector<std::pair<std::string, std::function<void(Param...)>>> options;

	/*!
	 * For each parameter, a list of values to test.
	 *
	 * A test will be ran for each combination of parameters. This is
	 * exponential in the number of parameters, so be conservative in the amount
	 * of parameters but also in the amount of values in each range!
	 */
	std::tuple<std::vector<Param>...> param_ranges;
};

}

#endif